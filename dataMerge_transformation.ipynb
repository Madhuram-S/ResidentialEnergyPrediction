{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Script to transform data\n",
    "\n",
    "The script focuses on bring RECS data from 2001, 2005, 2009 and 2015 into \n",
    "1. common format\n",
    "2. columns mapped correctly to the correct fields\n",
    "3. calaculations done as required\n",
    "4. elimination of columns not needed\n",
    "\n",
    "### Rules:\n",
    "1.\tAll columns starting with \"Z\" is dropped\n",
    "2.\tYearMade is converted to a range as per 2015 standards\n",
    "3.\tDrop 1997\n",
    "4.\tClub all electronics into 3 categories TVREL, PCOFFEQUIP, PHONE\n",
    "5.\tAll comsumption will be BTU and KWH will not be used\n",
    "6.\tCalucaled Fields\n",
    "    - \"2001 - TOTROOMS - sum(BEDROOMS,NCOMBATH,NHAFBATH,OTHROOMS)\"\n",
    "\t- TOTALBTU = TOTALBTUSPH + TOTALBTUWTH + TOTALBTUOTH\n",
    "\t- TOTALBTUSPH = BTULPSPH + BTUNGSPH + BTUFOSPH + BTUELSPH\n",
    "\t- TOTALBTUWTH = BTULPWTH + BTUNGWTH + BTUFOWTH + BTUELWTH\n",
    "\t- TOTALBTUOTH = BTULPAPL + BTUNGOTH + BTUFOAPL + BTUELOTH + BTUELFRG +BTUELCOL\n",
    "\t- TOTALDOLLAR = TOTALBTUSPH + TOTALBTUWTH + TOTALBTUOTH\n",
    "\t- TOTALDOLSPH = DOLLPSPH+ DOLNGSPH + DOLFOSPH + DOLELSPH\n",
    "\t- TOTALDOLWTH = DOLLPWTH+ DOLNGWTH+ DOLFOWTH+ DOLELWTH\n",
    "\t- TOTALDOLOTH = DOLLPOTH + DOLNGOTH+ DOLFOOTH + DOLELOTH + DOLELFRG + DOLELCOL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependecies\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Notebook Variables and Initialization\n",
    "dataFilePath = \"dataforfinalproject/RawDataFiles\"\n",
    "\n",
    "codebook_path = \"dataforfinalproject/RawDataFiles/Codebooks\"\n",
    "\n",
    "years = [2001, 2005, 2009, 2015]\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "dataFiles = ['target_final_2001.csv', \"RECS05alldata.csv\", \"recs2009_public.csv\", \"recs2015_public_v4.csv\"]\n",
    "\n",
    "col_list = ['2001_requiredCols.txt', '2005_requiredCols.txt', '2009_requiredCols.txt', '2015_requiredCols.txt']\n",
    "\n",
    "final_colList = \"final_columnList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2005\n",
      "2009\n",
      "2015\n"
     ]
    }
   ],
   "source": [
    "# read the files into a dataframe and compress dataframe to have only required cols\n",
    "for i, y in enumerate(years):\n",
    "    print(y)\n",
    "    df = pd.read_csv(os.path.join(dataFilePath, dataFiles[i]), low_memory=False)\n",
    "    l = pd.read_csv(os.path.join(codebook_path, col_list[i]), header= None, names = ['cols']).cols.tolist()\n",
    "    dfs[y] = df[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[2005] = pd.read_csv(os.path.join(dataFilePath, dataFiles[1]), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and tranform 2001 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Year of Survey to each of the datasets\n",
    "for y in years:\n",
    "    dfs[y]['RECSYEAR'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columnname YearMade to YearMadeRange\n",
    "dfs[2015].rename(columns = {\"YEARMADERANGE\":\"YEARMADE\"}, inplace = True)\n",
    "\n",
    "# change columnname Basefin to Cellar\n",
    "dfs[2005].rename(columns = {\"BASEFIN\":\"CELLAR\"}, inplace = True)\n",
    "dfs[2015].rename(columns = {\"BASEFIN\":\"CELLAR\"}, inplace = True)\n",
    "#dfs[2015].YEARMADE.head()\n",
    "\n",
    "# change OCCUPYYRANGE to OCCUPYY\n",
    "dfs[2015].rename(columns = {\"OCCUPYYRANGE\":\"OCCUPYY\"}, inplace = True)\n",
    "dfs[2009].rename(columns = {\"OCCUPYYRANGE\":\"OCCUPYY\"}, inplace = True)\n",
    "\n",
    "# change USENG to UGASHERE\n",
    "dfs[2009].rename(columns = {\"USENG\":\"UGASHERE\"}, inplace = True)\n",
    "\n",
    "# change TOAST to TOASTER in 2015\n",
    "dfs[2015].rename(columns = {\"TOAST\":\"TOASTER\"}, inplace = True)\n",
    "\n",
    "# change \"STOVENFU\" to \"STOVENFUEL\"\n",
    "dfs[2001].rename(columns = {\"STOVENFU\":\"STOVENFUEL\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"STOVENFU\":\"STOVENFUEL\"}, inplace = True)\n",
    "\n",
    "# rename columns OUTLGTNT(2001), NOUTLGTNT(2005, 2009) to LGTOUTNUM\n",
    "dfs[2001].rename(columns = {\"OUTLGTNT\":\"LGTOUTNUM\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"NOUTLGTNT\":\"LGTOUTNUM\"}, inplace = True)\n",
    "dfs[2009].rename(columns = {\"NOUTLGTNT\":\"LGTOUTNUM\"}, inplace = True)\n",
    "\n",
    "# rename ORIGIN1 to Householder_Race in 2001 and 2005\n",
    "dfs[2001].rename(columns = {\"ORIGIN1\":\"HOUSEHOLDER_RACE\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"ORIGIN1\":\"HOUSEHOLDER_RACE\"}, inplace = True)\n",
    "dfs[2009].rename(columns = {\"Householder_Race\":\"HOUSEHOLDER_RACE\"}, inplace = True)\n",
    "\n",
    "# rename CD65 and HD65 to CDD65 and HDD65\n",
    "dfs[2005].rename(columns = {\"CD65\":\"CDD65\", \"HD65\":\"HDD65\"}, inplace = True)\n",
    "\n",
    "# rename CORDS TO WOODAMT in 2001\n",
    "dfs[2001].rename(columns = {\"CORDS\":\"WOODAMT\"}, inplace = True)\n",
    "\n",
    "#change NGPAY to PGASHEAT for 2015\n",
    "dfs[2015].rename(columns = {\"NGPAY\": \"PGASHEAT\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate totrooms for 2001 data\n",
    "dfs[2001]['TOTROOMS'] = dfs[2001].BEDROOMS + dfs[2001].NCOMBATH  + dfs[2001].NHAFBATH +dfs[2001].OTHROOMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipAux_type = [\"REVERSE\",\"WARMAIR\",\"STEAMR\",\"PERMELEC\",\"PIPELESS\",\"ROOMHEAT\",\"WOODKILN\",\"CARRYEL\",\"CARRYKER\",\n",
    "                 \"CHIMNEY\",\"RANGE\",\"DIFEQUIP\"]\n",
    "for e in equipAux_type:\n",
    "    dfs[2015][e] = 0\n",
    "    \n",
    "dfs[2015].loc[dfs[2015].EQUIPAUXTYPE == 1,\"CARRYEL\"] = 1\n",
    "dfs[2015].loc[dfs[2015].EQUIPAUXTYPE == 2,'WOODKILN'] = 1\n",
    "dfs[2015].loc[dfs[2015].EQUIPAUXTYPE == 3,'PIPELESS'] = 1\n",
    "dfs[2015].loc[dfs[2015].EQUIPAUXTYPE == 4,'CHIMNEY'] = 1\n",
    "dfs[2015].loc[dfs[2015].EQUIPAUXTYPE == 9,'DIFEQUIP'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EquipAux types in 2001 to 2009, if value is -2 change it to 0\n",
    "for e in equipAux_type:\n",
    "    dfs[2001].loc[dfs[2001][e] == -2,e] = 0\n",
    "    dfs[2005].loc[dfs[2005][e] == -2,e] = 0\n",
    "    dfs[2009].loc[dfs[2009][e] == -2,e] = 0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipAux_fuel = [\"ELECAUX\",\"UGASAUX\",\"LPGAUX\",\"FOKRAUX\",\"WOODAUX\",\"OTHERAUX\"]\n",
    "\n",
    "for e in equipAux_fuel:\n",
    "    dfs[2015][e] = 0\n",
    "    dfs[2009][e] = 0\n",
    "    \n",
    "\n",
    "#2015 changes\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 1,\"UGASAUX\"] = 1\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 2,'LPGAUX'] = 1\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 3,'FOKRAUX'] = 1\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 5,'ELECAUX'] = 1\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 7,'WOODAUX'] = 1\n",
    "dfs[2015].loc[dfs[2015].FUELAUX == 21,'OTHERAUX'] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes to 2001 to 2005\n",
    "# combine the value for FO and Kero to one column and Solar into Other columns\n",
    "\n",
    "dfs[2001]['FOKRAUX'] = 0\n",
    "dfs[2005]['FOKRAUX'] = 0\n",
    "\n",
    "\n",
    "dfs[2001].loc[(dfs[2001]['FOILAUX'] == 1) | (dfs[2001]['KEROAUX'] == 1),\"FOKRAUX\"] = 1\n",
    "dfs[2005].loc[(dfs[2005]['FOILAUX'] == 1) | (dfs[2005]['KEROAUX'] == 1),\"FOKRAUX\"] = 1\n",
    "\n",
    "dfs[2001].loc[(dfs[2001]['SOLARAUX'] == 1) | (dfs[2001]['OTHERAUX'] == 1),\"OTHERAUX\"] = 1\n",
    "dfs[2005].loc[(dfs[2005]['SOLARAUX'] == 1) | (dfs[2005]['OTHERAUX'] == 1),\"OTHERAUX\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in equipAux_fuel:\n",
    "    dfs[2001].loc[dfs[2001][e] == -2,e] = 0\n",
    "    dfs[2005].loc[dfs[2005][e] == -2,e] = 0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 2009 Auxillary fuel type to standard fuel types as specified in years (2001, 2005 and 2015)\n",
    "equipAux_fuel_2009 = [\"FURNFUEL\",\"RADFUEL\",\"PIPEFUEL\",\"RMHTFUEL\",\"HSFUEL\",\"FPFUEL\",\"RNGFUEL\",\"DIFFUEL\"]\n",
    "for e in equipAux_fuel_2009:\n",
    "    dfs[2009].loc[dfs[2009][e] == 1,\"UGASAUX\"] = 1\n",
    "    dfs[2009].loc[dfs[2009][e] == 2,'LPGAUX'] = 1\n",
    "    dfs[2009].loc[(dfs[2009][e] == 3) | (dfs[2009][e] == 4) ,'FOKRAUX'] = 1\n",
    "    dfs[2009].loc[dfs[2009][e] == 5,'ELECAUX'] = 1\n",
    "    dfs[2009].loc[dfs[2009][e] == 7,'WOODAUX'] = 1\n",
    "    dfs[2009].loc[dfs[2009][e] > 7,'OTHERAUX'] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the value for Energy Star Dishwasher for 2001 based on other years\n",
    "# currently go with -9 as no data has been recorded for this\n",
    "dfs[2001]['ESDISHW'] = -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all categories of BTU usage into BTUXXOTH\n",
    "# --- Electric\n",
    "dfs[2001]['BTUELOTH'] = dfs[2001][[\"BTUELAPL\",\"BTUELFZZ\",\"BTUELDWH\",\"BTUELCDR\"]].sum(axis = 1)\n",
    "dfs[2005]['BTUELOTH'] = dfs[2005][[\"BTUELAPL\",\"BTUELFZZ\",\"BTUELDWH\",\"BTUELCDR\"]].sum(axis = 1)\n",
    "dfs[2015]['BTUELOTH'] = dfs[2015][[\"BTUELRFG1\",\"BTUELRFG2\",\"BTUELFRZ\",\"BTUELCOK\",\"BTUELMICRO\",\"BTUELCW\",\"BTUELCDR\",\\\n",
    "                                \"BTUELDWH\",\"BTUELLGT\",\"BTUELTVREL\",\"BTUELTV1\",\"BTUELTV2\",\"BTUELAHUHEAT\",\"BTUELAHUCOL\",\\\n",
    "                                   \"BTUELEVAPCOL\",\"BTUELCFAN\",\"BTUELDHUM\",\"BTUELHUM\",\"BTUELPLPMP\",\"BTUELHTBPMP\",\"BTUELHTBHEAT\",\\\n",
    "                                   \"BTUELNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- LPG\n",
    "dfs[2001].rename(columns = {\"BTULPAPL\":\"BTULPOTH\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"BTULPAPL\":\"BTULPOTH\"}, inplace = True)\n",
    "dfs[2015]['BTULPOTH'] = dfs[2015][[\"BTULPCOK\",\"BTULPCDR\",\"BTULPNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- Natural Gas\n",
    "dfs[2001].rename(columns = {\"BTUNGAPL\":\"BTUNGOTH\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"BTUNGAPL\":\"BTUNGOTH\"}, inplace = True)\n",
    "dfs[2015]['BTUNGOTH'] = dfs[2015][[\"BTUNGCOK\",\"BTUNGCDR\",\"BTUNGPLHEAT\",\"BTUNGHTBHEAT\",\"BTUNGNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- Fuel Oil\n",
    "dfs[2001]['BTUFOOTH'] = dfs[2001][[\"BTUFOAPL\",\"BTUKRAPL\"]].sum(axis = 1)\n",
    "dfs[2005].rename(columns = {\"BTUFOAPL\":\"BTUFOOTH\"}, inplace = True)\n",
    "dfs[2015].rename(columns = {\"BTUFONEC\":\"BTUFOOTH\"}, inplace = True)\n",
    "\n",
    "# for 2001, merge the total for BTU from FO and Kerosene into one col\n",
    "dfs[2001]['BTUFOSPH'] = dfs[2001][[\"BTUFOSPH\",\"BTUKRSPH\"]].sum(axis = 1)\n",
    "dfs[2001]['BTUFOWTH'] = dfs[2001][[\"BTUFOWTH\",\"BTUKRWTH\"]].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all categories of DOL usage into DOLXXOTH\n",
    "# --- Electric\n",
    "dfs[2001]['DOLELOTH'] = dfs[2001][[\"DOLELAPL\",\"DOLELFZZ\",\"DOLELDWH\",\"DOLELCDR\"]].sum(axis = 1)\n",
    "dfs[2005]['DOLELOTH'] = dfs[2005][[\"DOLELAPL\",\"DOLELFZZ\",\"DOLELDWH\",\"DOLELCDR\"]].sum(axis = 1)\n",
    "dfs[2015]['DOLELOTH'] = dfs[2015][[\"DOLELRFG1\",\"DOLELRFG2\",\"DOLELFRZ\",\"DOLELCOK\",\"DOLELMICRO\",\"DOLELCW\",\"DOLELCDR\",\\\n",
    "                                   \"DOLELDWH\",\"DOLELLGT\",\"DOLELTVREL\",\"DOLELTV1\",\"DOLELTV2\",\"DOLELAHUHEAT\",\"DOLELAHUCOL\",\\\n",
    "                                   \"DOLELCFAN\",\"DOLELDHUM\",\"DOLELHUM\",\"DOLELPLPMP\",\"DOLELHTBPMP\",\"DOLELHTBHEAT\",\\\n",
    "                                   \"DOLELNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- LPG\n",
    "dfs[2001].rename(columns = {\"DOLLPAPL\":\"DOLLPOTH\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"DOLLPAPL\":\"DOLLPOTH\"}, inplace = True)\n",
    "dfs[2015]['DOLLPOTH'] = dfs[2015][[\"DOLLPCOK\",\"DOLLPCDR\",\"DOLLPNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- Natural Gas\n",
    "dfs[2001].rename(columns = {\"DOLNGAPL\":\"DOLNGOTH\"}, inplace = True)\n",
    "dfs[2005].rename(columns = {\"DOLNGAPL\":\"DOLNGOTH\"}, inplace = True)\n",
    "dfs[2015]['DOLNGOTH'] = dfs[2015][[\"DOLNGCOK\",\"DOLNGCDR\",\"DOLNGPLHEAT\",\"DOLNGHTBHEAT\",\"DOLNGNEC\"]].sum(axis = 1)\n",
    "\n",
    "# --- Fuel Oil\n",
    "dfs[2001]['DOLFOOTH'] = dfs[2001][[\"DOLFOAPL\",\"DOLKRAPL\"]].sum(axis = 1)\n",
    "dfs[2005].rename(columns = {\"DOLFOAPL\":\"DOLFOOTH\"}, inplace = True)\n",
    "dfs[2015].rename(columns = {\"DOLFONEC\":\"DOLFOOTH\"}, inplace = True)\n",
    "\n",
    "# for 2001, merge the total for DOL from FO and Kerosene into one col\n",
    "dfs[2001]['DOLFOSPH'] = dfs[2001][[\"DOLFOSPH\",\"DOLKRSPH\"]].sum(axis = 1)\n",
    "dfs[2001]['DOLFOWTH'] = dfs[2001][[\"DOLFOWTH\",\"DOLKRWTH\"]].sum(axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TOTAL BTU VALUES\n",
    "# --- BY end use\n",
    "# TOTALBTU = TOTALBTUSPH + TOTALBTUWTH + TOTALBTUOTH\n",
    "# TOTALBTUSPH = BTULPSPH + BTUNGSPH + BTUFOSPH + BTUELSPH\n",
    "# TOTALBTUWTH = BTULPWTH + BTUNGWTH + BTUFOWTH + BTUELWTH\n",
    "# TOTALBTUOTH = BTULPAPL + BTUNGOTH + BTUFOAPL + BTUELOTH + BTUELFRG +BTUELCOL\n",
    "# TOTALDOLLAR = TOTALDOLSPH + TOTALDOLWTH + TOTALDOLOTH\n",
    "# TOTALDOLSPH = DOLLPSPH+ DOLNGSPH + DOLFOSPH + DOLELSPH\n",
    "# TOTALDOLWTH = DOLLPWTH+ DOLNGWTH+ DOLFOWTH+ DOLELWTH\n",
    "# TOTALDOLOTH = DOLLPOTH + DOLNGOTH+ DOLFOOTH + DOLELOTH + DOLELFRG + DOLELCOL\n",
    "\n",
    "# --- Totals by end use\n",
    "for y in years:\n",
    "    dfs[y]['TOTALBTUSPH'] = dfs[y][[\"BTULPSPH\",\"BTUNGSPH\",\"BTUFOSPH\",\"BTUELSPH\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALBTUWTH'] = dfs[y][[\"BTULPWTH\",\"BTUNGWTH\",\"BTUFOWTH\",\"BTUELWTH\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALBTUOTH'] = dfs[y][[\"BTULPOTH\",\"BTUNGOTH\",\"BTUFOOTH\",\"BTUELOTH\",\"BTUELCOL\",\"BTUELRFG\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALBTU'] = dfs[y][[\"TOTALBTUSPH\",\"TOTALBTUWTH\",\"TOTALBTUOTH\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALDOLSPH'] = dfs[y][[\"DOLLPSPH\",\"DOLNGSPH\",\"DOLFOSPH\",\"DOLELSPH\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALDOLWTH'] = dfs[y][[\"DOLLPWTH\",\"DOLNGWTH\",\"DOLFOWTH\",\"DOLELWTH\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALDOLOTH'] = dfs[y][[\"DOLLPOTH\",\"DOLNGOTH\",\"DOLFOOTH\",\"DOLELOTH\",\"DOLELCOL\",\"DOLELRFG\"]].sum(axis = 1)\n",
    "    dfs[y]['TOTALDOLLAR'] = dfs[y][[\"TOTALDOLSPH\",\"TOTALDOLWTH\",\"TOTALDOLOTH\"]].sum(axis = 1)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TV/AUDIO/STEREO into one col TVAUDIOEQUIP\n",
    "# 2001 - \"TVCOLOR\", \"BIGTV\", \"VCR\",\"STEREO\",\"BOOMBOX\",\"COMPCTST\",\"COMPNTST\",\"OTHSTER\"   \n",
    "\n",
    "dfs[2001]['TVAUDIOEQUIP'] = dfs[2001][[\"TVCOLOR\", \"BIGTV\", \"VCR\",\"STEREO\",\"BOOMBOX\",\"COMPCTST\",\"COMPNTST\",\"OTHSTER\"]].\\\n",
    "                                    sum(axis = 1)\n",
    "\n",
    "#2005 - first replace 99 with 0 and then add all fields\n",
    "appl_2005 = [\"TVCOLOR\",\"BIGTV\",\"PLASMANUM\",\"VCR\",\"DVD\",\"NCOMBOVCRDVD\",\"PLAYSTA\",\"STEREO\",\"BOOMBOX\",\"COMPCTST\",\"COMPNTST\",\"OTHSTER\"]\n",
    "for a in appl_2005:\n",
    "    dfs[2005][a] = dfs[2005][a].apply(lambda r : r if r != 99 else 0)\n",
    "\n",
    "dfs[2005]['TVAUDIOEQUIP'] = dfs[2005][appl_2005].sum(axis=1)\n",
    "\n",
    "#2009 - \n",
    "appl_2009 = [\"TVCOLOR\",\"COMBODVR1\",\"DVR1\",\"DIGITSTB1\",\"PLAYSTA1\",\"COMBOVCRDVD1\",\"VCR1\",\"DVD1\",\"TVAUDIOSYS1\",\"OTHERSTB1\",\"CABLESAT2\",\"COMBODVR2\",\"DVR2\",\"DIGITSTB2\",\"PLAYSTA2\",\"COMBOVCRDVD2\",\"VCR2\",\"DVD2\",\"TVAUDIOSYS2\",\"OTHERSTB2\",\"CABLESAT3\",\"COMBODVR3\",\"DVR3\",\"DIGITSTB3\",\"PLAYSTA3\",\"COMBOVCRDVD3\",\"VCR3\",\"DVD3\",\"TVAUDIOSYS3\",\"OTHERSTB3\"]\n",
    "\n",
    "for a in appl_2009:\n",
    "    dfs[2009][a] = dfs[2009][a].apply(lambda r : r if r != -2 else 0)\n",
    "\n",
    "dfs[2009]['TVAUDIOEQUIP'] = dfs[2009][appl_2009].sum(axis=1)\n",
    "\n",
    "#2015\n",
    "appl_2015 = [\"TVCOLOR\",\"CABLESAT\",\"COMBODVR\",\"SEPDVR\",\"PLAYSTA\",\"DVD\",\"VCR\",\"INTSTREAM\",\"TVAUDIOSYS\"]\n",
    "for a in appl_2015:\n",
    "    dfs[2015][a] = dfs[2015][a].apply(lambda r : r if r != -2 else 0)\n",
    "\n",
    "dfs[2015]['TVAUDIOEQUIP'] = dfs[2015][appl_2015].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PC and OFFICE  into one col PCOFFEQUIP\n",
    "\n",
    "pc_2001 = [\"NUMPC\",\"LAPTOPPC\",\"PCPRINT\",\"FXCOPIER\",\"FAX\",\"COPIER\"]\n",
    "for p in pc_2001:\n",
    "    dfs[2001][p] = dfs[2001][p].apply(lambda r : r if r != 99 else 0)\n",
    "    dfs[2001][p] = dfs[2001][p].apply(lambda r : r if r != 9 else 0)\n",
    "    \n",
    "dfs[2001]['PCOFFEQUIP'] = dfs[2001][pc_2001].sum(axis = 1)\n",
    "\n",
    "#2005 - first replace 99 or 9 with 0 and then add all fields\n",
    "pc_2005 = [\"NUMPC\",\"LAPTOPPC\",\"PCPRINT\",\"FXCOPIER\",\"FAX\",\"COPIER\"]\n",
    "monitor = [\"MONITOR1\",\"MONITOR2\",\"MONITOR3\"]\n",
    "for p in pc_2005:\n",
    "    dfs[2005][p] = dfs[2005][p].apply(lambda r : r if (r != 99) else 0)\n",
    "    dfs[2005][p] = dfs[2005][p].apply(lambda r : r if (r != 9) else 0)\n",
    "for m in monitor:\n",
    "    dfs[2005][m] = dfs[2005][m].apply(lambda r : r if (r != 99) else 0)\n",
    "    dfs[2005][m] = dfs[2005][m].apply(lambda r : r if (r != 9) else 0)\n",
    "    dfs[2005][m] = dfs[2005][m].apply(lambda r : r if (r != 2) else 1)    \n",
    "    \n",
    "dfs[2005]['PCOFFEQUIP'] = dfs[2005][pc_2005].sum(axis = 1) + dfs[2005][monitor].sum(axis = 1)\n",
    "\n",
    "#2009 - \n",
    "pc_2009 = [\"NUMPC\",\"PCPRINT\",\"FAX\",\"COPIER\"]\n",
    "monitor = [\"MONITOR1\",\"MONITOR2\",\"MONITOR3\"]\n",
    "for p in pc_2009:\n",
    "    dfs[2009][p] = dfs[2009][p].apply(lambda r : r if (r != -2) else 0)\n",
    "for m in monitor:\n",
    "    dfs[2009][m] = dfs[2009][m].apply(lambda r : r if (r != 0) else 1)\n",
    "    dfs[2009][m] = dfs[2009][m].apply(lambda r : r if (r != -2) else 0)    \n",
    "    \n",
    "dfs[2009]['PCOFFEQUIP'] = dfs[2009][pc_2009].sum(axis = 1) + dfs[2009][monitor].sum(axis = 1)\n",
    "\n",
    "#2015\n",
    "pc_2015 = [\"DESKTOP\",\"NUMLAPTOP\",\"NUMTABLET\",\"ELPERIPH\"]\n",
    "\n",
    "dfs[2015]['PCOFFEQUIP'] = dfs[2015][pc_2015].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUMSMPHONE     8\n",
       "CELLPHONE     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[2015][[\"NUMSMPHONE\",\"CELLPHONE\"]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine All phone and phone related   into one col PHONE\n",
    "\n",
    "ph_01_05 = [\"NOCORD\",\"CELLPHON\",\"ANSMACH\"]\n",
    " \n",
    "#2001\n",
    "dfs[2001]['PHONE'] = dfs[2001][ph_01_05].sum(axis = 1)\n",
    "#2005\n",
    "dfs[2005]['PHONE'] = dfs[2005][ph_01_05].sum(axis = 1)\n",
    "\n",
    "#2009 - \n",
    "ph_2009 = [\"NOCORD\",\"ANSMACH\"]\n",
    "dfs[2009]['PHONE'] = dfs[2009][ph_2009].sum(axis = 1)\n",
    "\n",
    "#2015\n",
    "ph_2015 = [\"NUMSMPHONE\",\"CELLPHONE\"]\n",
    "\n",
    "dfs[2015]['PHONE'] = dfs[2015][ph_2015].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "235\n",
      "246\n",
      "276\n"
     ]
    }
   ],
   "source": [
    "print(len(dfs[2001].columns))\n",
    "print(len(dfs[2005].columns))\n",
    "print(len(dfs[2009].columns))\n",
    "print(len(dfs[2015].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnl_cols = pd.read_csv(os.path.join(codebook_path, final_colList), header= None, names = ['cols']).cols.tolist()\n",
    "len(fnl_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with NAN Values in 2001 datase : []\n",
      "columns with NAN Values in 2005 datase : []\n",
      "columns with NAN Values in 2009 datase : []\n",
      "columns with NAN Values in 2015 datase : []\n"
     ]
    }
   ],
   "source": [
    "print(f\"columns with NAN Values in 2001 datase : {dfs[2001].columns[dfs[2001].isna().any()].tolist()}\")\n",
    "print(f\"columns with NAN Values in 2005 datase : {dfs[2005].columns[dfs[2005].isna().any()].tolist()}\")\n",
    "print(f\"columns with NAN Values in 2009 datase : {dfs[2009].columns[dfs[2009].isna().any()].tolist()}\")\n",
    "print(f\"columns with NAN Values in 2015 datase : {dfs[2015].columns[dfs[2015].isna().any()].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with NAN Values in 2005 datase : []\n",
      "columns with NAN Values in 2005 dataset after NA FIX : []\n"
     ]
    }
   ],
   "source": [
    "# This exists for only for 2005\n",
    "# for the columns with NA, fill it with Mean value of the column\n",
    "dfs[2005].fillna(dfs[2005].mean(), inplace = True)\n",
    "\n",
    "print(f\"columns with NAN Values in 2005 dataset after NA FIX : {dfs[2005].columns[dfs[2005].isna().any()].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_frame = [dfs[2001][fnl_cols],dfs[2005][fnl_cols],dfs[2009][fnl_cols],dfs[2015][fnl_cols]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_DF = pd.DataFrame(columns = fnl_cols)\n",
    "# combined_DF = dfs_list[2].append(dfs_list[3], ignore_index = True)\n",
    "combined_df = pd.concat(dfs_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with NAN Values in combined datase : []\n"
     ]
    }
   ],
   "source": [
    "print(f\"columns with NAN Values in combined datase : {combined_df.columns[combined_df.isna().any()].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count of records in Combined dataset: 26973\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Count of records in Combined dataset: {combined_df.DOEID.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write file to csv\n",
    "combined_df.to_csv(os.path.join(\"./dataforfinalproject\", \"RECS_COMBINED_DATA.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
